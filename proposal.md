# Proposal

## What will happen in your session? (150 words)

Algorithmic systems are increasingly used to make important decisions about our lives; from the content we see on the web, to the job offers and credit scores we receive. These systems use machine learning techniques to learn from past data to predict the future. But itâ€™s not easy to understand why they make the predictions that they do. And if they learn from data generated in a society full of bias and discrimination, they may end up reproducing these undesirable patterns. In this interactive session, participants will learn how to open up algorithmic black boxes, to derive explanations for their decisions, and discover their biases and quirks. We will try out a new explanation tool (LIME) which can explain the decisions of any classifier, whether the input is text or images. Using a web-based interactive environment (a JuPyter notebook), we will get hands-on with real datasets, models and code.

## What is the goal or outcome of your session? (120 words)

Participants will have learned how to detect biases and explain the decisions of the machine learning models behind many of the systems that affect our lives. In groups, they will have investigated models trained on specific datasets to uncover how they work and their potential biases. Participants will come away with a greater understanding of how biases can arise in algorithmic systems, which will help them to advocate for responsible use of data in their communities, companies and platforms.

## After the festival, how will you and your participants take the learning and activities forward? (120 words)

Based on these activities, we will create an open, collaborative index of the biases and quirks discovered by participants in each model, which can be added to and used as a reference for further exploration. As participants take these skills into their own contexts, they can contribute their findings and lessons learned. Think of it like a Wiki / Stack Exchange for fair and transparent data science. We hope that this can serve as a useful learning tool and open resource for data scientists and users to promote more ethical use of algorithms.

## How will you deal with varying numbers of participants in your session? What if 30 participants attend? What if there are 3? (120 words)

We will have up to 5 facilitators available to assist participants with the exercise, and to help support each group in their investigation. We will ensure that there 5 different datasets and models so that each group can investigate a different context. If there are only a small number participants, we can focus on a smaller number of contexts in greater detail.
